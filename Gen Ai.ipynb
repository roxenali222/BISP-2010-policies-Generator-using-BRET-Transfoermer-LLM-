{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_file = \"BISP_ACT_2010.pdf\"  # Replace with your file path\n",
    "doc = fitz.open(pdf_file)\n",
    "\n",
    "# Initialize an empty string to store all text\n",
    "all_text = \"\"\n",
    "\n",
    "# Loop through each page\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)  # Load the page\n",
    "    all_text += page.get_text(\"text\")  # Extract text in 'text' mode\n",
    "\n",
    "# Print or process the text\n",
    "print(all_text)\n",
    "\n",
    "# Always remember to close the document after you're done\n",
    "doc.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF for extracting text from PDF\n",
    "import spacy\n",
    "\n",
    "# Load the SpaCy language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "pdf_file = \"BISP_ACT_2010.pdf\"\n",
    "doc = fitz.open(pdf_file)\n",
    "all_text = \"\"\n",
    "\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    all_text += page.get_text(\"text\")\n",
    "\n",
    "doc.close()\n",
    "\n",
    "# Step 2: Use SpaCy for Text Preprocessing\n",
    "# Process the extracted text with SpaCy\n",
    "doc = nlp(all_text)\n",
    "\n",
    "# Filter out stopwords, punctuation, and perform lemmatization\n",
    "cleaned_text = []\n",
    "for token in doc:\n",
    "    if not token.is_stop and not token.is_punct:\n",
    "        cleaned_text.append(token.lemma_)\n",
    "\n",
    "# Join the tokens back into a cleaned string\n",
    "final_cleaned_text = \" \".join(cleaned_text)\n",
    "\n",
    "# Print the cleaned text\n",
    "print(final_cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (75.1.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.44.0)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312;c:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\nodejs\\;C:\\Program Files\\Git\\cmd;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Admin\\.dotnet\\tools;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Roaming\\npm;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\nodejs\\;C:\\Program Files\\Git\\cmd;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\;C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\;C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Admin\\.dotnet\\tools;C:\\Users\\Admin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\Admin\\AppData\\Roaming\\npm\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "! C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install numpy<2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # pre-trained BERT model and tokenizer\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "inputs = tokenizer(final_cleaned_text, return_tensors='pt', truncation=True, padding=True, max_length=5112)  # Tokenize the extracted text\n",
    "\n",
    "with torch.no_grad():  # Get embeddings for the tokenized text\n",
    "    outputs = model(**inputs)\n",
    "embeddings = outputs.last_hidden_state  \n",
    "print(embeddings.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0534, -0.4177, -0.3749,  ..., -0.3731, -0.3823,  0.3369],\n",
       "         [ 1.0349, -0.0260, -0.3147,  ...,  0.0684, -0.6370, -0.4395]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0:3] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 799.2 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 987.4 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.0/1.2 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.11.0\n",
      "    Uninstalling keras-2.11.0:\n",
      "      Successfully uninstalled keras-2.11.0\n",
      "Successfully installed keras-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n",
      "[-1.18838392e-01  4.82986979e-02 -2.54806248e-03 -1.10111516e-02\n",
      "  5.19507416e-02  1.02917831e-02  1.15433306e-01  7.00765639e-04\n",
      " -8.59253854e-02 -7.06539974e-02  1.33173517e-03 -3.54723446e-02\n",
      "  1.84341371e-02 -6.73719356e-03  2.44030301e-02 -2.95032207e-02\n",
      " -5.81383780e-02 -5.04395850e-02 -2.07654722e-02  2.90360302e-02\n",
      " -6.36759177e-02  2.40299068e-02  2.62432769e-02 -6.03737356e-03\n",
      " -1.10765072e-02 -1.40067691e-03 -1.86198503e-02  3.27700824e-02\n",
      "  2.88605364e-03 -5.69439456e-02 -4.39416133e-02  2.54140366e-02\n",
      "  8.79094526e-02 -2.49912236e-02 -3.66832241e-02  6.24138303e-03\n",
      " -6.64678738e-02 -6.71444982e-02  2.05642302e-02  4.23887596e-02\n",
      "  2.18801927e-02 -4.28824723e-02 -3.43769863e-02  6.14668988e-02\n",
      "  6.56372905e-02 -7.85202906e-02  2.94870343e-02  1.07983146e-02\n",
      "  6.33240938e-02 -4.50847112e-02 -1.82339512e-02 -2.77210772e-02\n",
      " -3.67375044e-03 -3.65945399e-02  5.42502403e-02 -2.08565500e-02\n",
      "  1.50349047e-02 -6.00951575e-02  1.63938776e-02 -3.32385637e-02\n",
      "  1.75034814e-02 -5.95171528e-04 -1.63483784e-01  8.49208534e-02\n",
      " -7.58384690e-02  1.61097329e-02  4.83829156e-02 -7.59812538e-03\n",
      " -2.49854494e-02  5.94974831e-02  6.58900961e-02 -3.51374559e-02\n",
      "  8.84329027e-04 -1.15679756e-01  4.93903719e-02  3.36045921e-02\n",
      "  5.51542155e-02  2.63836998e-02  5.36944456e-02  3.89324725e-02\n",
      "  4.39348805e-04  1.80604700e-02 -9.28825513e-02 -4.07398725e-03\n",
      " -8.23470298e-04 -4.88310978e-02 -6.67745806e-03 -2.35417131e-02\n",
      " -3.81330475e-02  5.24516664e-02 -4.24938202e-02 -5.58997467e-02\n",
      "  8.68157744e-02 -4.89616878e-02 -8.33967477e-02 -4.57635261e-02\n",
      "  2.90422160e-02  3.46577466e-02 -8.64917934e-02  4.06218499e-01\n",
      "  3.59494574e-02  1.86971277e-02  9.79784131e-02 -7.86515884e-03\n",
      "  2.37140935e-02 -5.75650595e-02 -6.10998645e-02 -6.62050210e-03\n",
      "  7.06002628e-03  2.16698684e-02 -2.44051442e-02 -3.35146189e-02\n",
      "  2.50156823e-04  3.17076594e-02  4.40716408e-02  9.46324468e-02\n",
      " -3.55800427e-02 -4.53427900e-03  4.37148288e-02  2.05009623e-04\n",
      " -2.85876053e-03 -2.48841010e-02  3.76065355e-03  1.40412943e-02\n",
      "  7.78158531e-02 -1.32314429e-01  6.87646400e-03 -7.22012581e-33\n",
      "  7.33462023e-03  2.72619119e-03  1.21475849e-02 -2.44025816e-03\n",
      "  2.79325396e-02  3.92706841e-02  3.74390814e-03 -4.64353189e-02\n",
      " -1.44925658e-02  5.36019728e-02  6.59060339e-03  3.66479084e-02\n",
      " -2.31356993e-02  3.27537060e-02  7.81107843e-02  9.62749775e-03\n",
      "  7.96414912e-03  2.87428848e-03 -1.88071071e-03  4.69157286e-03\n",
      " -1.24022868e-02 -8.04160256e-04 -2.30386779e-02  4.29729670e-02\n",
      " -2.82599553e-02 -6.69464841e-02  3.85390669e-02 -7.08571449e-02\n",
      "  2.01092474e-02  1.46031682e-03  1.46395154e-03  4.99123111e-02\n",
      " -2.59455293e-02  8.22350092e-04 -3.75727303e-02 -2.87406687e-02\n",
      "  3.33751440e-02 -7.46282935e-02 -3.59839648e-02  2.56807879e-02\n",
      " -5.01390658e-02  1.08372094e-02 -4.24379259e-02 -2.66856211e-03\n",
      " -4.91626654e-03  1.66479230e-01 -1.15409750e-03 -4.96064685e-03\n",
      " -6.48221150e-02  6.97621182e-02 -2.81823310e-03 -2.13251915e-02\n",
      " -1.16136968e-01  4.33387011e-02 -3.35092633e-03 -2.01065168e-02\n",
      "  1.65539850e-02 -4.39711772e-02  2.06194725e-02 -9.08998214e-03\n",
      "  9.71362554e-03  3.93914580e-02 -1.24877524e-02  9.35027841e-03\n",
      " -8.64778683e-02 -4.85176742e-02  2.44777780e-02 -8.49497598e-03\n",
      "  2.30636317e-02 -1.26381991e-02 -5.10100126e-02  3.67599577e-02\n",
      "  3.77173796e-02  3.09161097e-02 -2.87985057e-02 -1.92688014e-02\n",
      " -1.98317114e-02  3.58351506e-02  8.06304738e-02  6.49731467e-03\n",
      "  3.54552753e-02 -4.19589169e-02  6.69379253e-03 -2.40788702e-02\n",
      "  9.50236768e-02  5.46350256e-02  4.22102492e-03 -5.18072993e-02\n",
      "  1.02151679e-02 -4.10986766e-02 -3.57456133e-02  6.13181703e-02\n",
      " -3.09442054e-03  8.79615694e-02  6.00077678e-03  4.49256419e-33\n",
      " -7.71673843e-02  1.89931504e-02 -3.57381813e-02  8.87978747e-02\n",
      " -1.75550971e-02 -2.76269484e-03  3.72739919e-02  9.01368111e-02\n",
      " -9.25045237e-02  6.80299401e-02  2.23901942e-02 -4.50896882e-02\n",
      "  3.08789201e-02  4.44951691e-02 -5.79960970e-03  3.52335982e-02\n",
      "  6.96884170e-02 -4.06348798e-03 -2.81551033e-02 -3.57293934e-02\n",
      " -3.05071808e-02 -3.23784351e-02 -2.49985117e-03  3.49294282e-02\n",
      " -4.14807461e-02  3.02052572e-02  4.85891029e-02  6.32988065e-02\n",
      " -2.16931663e-02  3.68005037e-02  3.89656909e-02 -2.35814750e-02\n",
      " -5.06325960e-02 -5.82029708e-02  4.82625179e-02  8.40439349e-02\n",
      "  3.67811620e-02 -7.76893750e-04  2.48482134e-02 -5.05173430e-02\n",
      "  3.96689475e-02 -1.00827739e-02  2.24443595e-03  1.16977192e-01\n",
      " -2.19612904e-02 -5.80592919e-03 -4.80928831e-02  3.78890173e-03\n",
      "  3.51726450e-02  7.72971883e-02 -9.31971371e-02 -1.19929090e-02\n",
      " -2.19681263e-02  4.12943289e-02 -2.29583159e-02  4.16047731e-03\n",
      " -4.32187170e-02  7.02132210e-02 -1.90595184e-02  4.75232722e-04\n",
      "  5.48061589e-03  2.67614555e-02 -3.36127244e-02  1.34685216e-02\n",
      " -2.27466710e-02  3.87389548e-02 -2.45232973e-02 -3.63281667e-02\n",
      " -1.79244578e-03 -5.25699258e-02  6.68941345e-03 -2.58465465e-02\n",
      " -1.34835348e-01  1.13944383e-03 -4.71692905e-02 -5.34749106e-02\n",
      " -1.84271038e-02 -7.30416086e-03 -9.65709332e-03 -3.77261341e-02\n",
      " -3.39998417e-02  1.84173845e-02 -8.00314918e-03 -5.51235816e-03\n",
      " -3.35320011e-02 -2.01806184e-02  2.16657780e-02  1.07582817e-02\n",
      " -5.74747398e-02  1.96968466e-02 -7.24083185e-03  2.30370965e-02\n",
      "  1.20234050e-01  3.24197067e-03  1.01500852e-02 -1.34036666e-08\n",
      " -4.67245765e-02  4.06206809e-02 -5.56163788e-02 -1.88535836e-03\n",
      "  5.63239828e-02  4.96388413e-02 -4.15416174e-02  3.25038433e-02\n",
      "  2.57492196e-02 -1.87809989e-02  6.92081302e-02  2.59879474e-02\n",
      " -2.78233290e-02  5.75751290e-02  9.12809372e-02 -1.53257903e-02\n",
      " -1.04720943e-01 -2.75859758e-02 -1.62227731e-02 -3.53993177e-02\n",
      " -1.04613109e-02 -1.39993448e-02 -2.94040627e-04 -8.36297497e-02\n",
      "  7.93233979e-03  6.96005300e-03 -4.42297980e-02  7.47581646e-02\n",
      "  7.44095743e-02 -4.05807644e-02 -1.82669598e-03  1.98500454e-02\n",
      "  1.43821593e-02  2.05854084e-02  2.21337751e-02 -6.43705130e-02\n",
      " -6.36985302e-02  1.61391385e-02  9.90733877e-03 -5.55954315e-03\n",
      " -5.46731465e-02 -2.33115032e-02  7.04692751e-02  6.46799803e-03\n",
      " -4.77000475e-02 -3.64709273e-03  7.83759356e-03 -4.97461436e-03\n",
      " -1.24185681e-02 -7.78121501e-02 -9.40944068e-04 -8.00253265e-03\n",
      "  6.03420241e-03  8.43493491e-02  1.07303746e-01  1.14277322e-02\n",
      "  1.33667067e-02 -1.27473613e-02  6.14543967e-02  3.56412940e-02\n",
      "  1.58745885e-01  1.26409471e-01  4.65490893e-02 -1.57172792e-02]\n"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 1: Extract text from PDF\n",
    "pdf_file = \"BISP_ACT_2010.pdf\"\n",
    "doc = fitz.open(pdf_file)\n",
    "all_text = \"\"\n",
    "\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    all_text += page.get_text(\"text\")\n",
    "\n",
    "doc.close()\n",
    "\n",
    "# Step 2: Load a pre-trained Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 3: Tokenize and encode sentences into embeddings\n",
    "sentences = all_text.split(\"\\n\")  \n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# Step 4: Output embeddings\n",
    "print(sentence_embeddings.shape)  # (number_of_sentences, embedding_dimension)\n",
    "print(sentence_embeddings[0])     # Print embedding of the first sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [03:57<?, ?it/s]\n",
      "100%|██████████| 3/3 [02:09<00:00, 43.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 128.9126, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.023, 'train_loss': 6.597178141276042, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=6.597178141276042, metrics={'train_runtime': 128.9126, 'train_samples_per_second': 0.023, 'train_steps_per_second': 0.023, 'total_flos': 783876096000.0, 'train_loss': 6.597178141276042, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of samples in the dataset\n",
    "num_samples = len(tokenized_policy_dataset['train'])\n",
    "\n",
    "# Use the whole dataset if there are not enough samples to split\n",
    "if num_samples < 10:  # Adjust this threshold as needed\n",
    "    train_dataset = tokenized_policy_dataset['train']\n",
    "    eval_dataset = None  # No validation dataset\n",
    "else:\n",
    "    # Split the dataset into train and validation\n",
    "    split_dataset = tokenized_policy_dataset['train'].train_test_split(test_size=0.1)\n",
    "    train_dataset = split_dataset['train']\n",
    "    eval_dataset = split_dataset['test']\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-policy-model\",\n",
    "    evaluation_strategy=\"epoch\" if eval_dataset is not None else \"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset  # This will be None if eval_dataset is not available\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_dataset is not None:\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(eval_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./gpt2-policy-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your policy prompt here.\n",
      "\n",
      "The following is a list of the most popular and popular policies.\n",
      "\n",
      "The most popular policy prompt here.\n",
      "\n",
      "The most popular policy prompt here.\n",
      "\n",
      "The most popular policy policy prompt here.\n",
      "\n",
      "The most popular policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The most policy prompt here.\n",
      "\n",
      "The\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Your policy prompt here\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(input_ids, max_length=150)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad token to eos token (if you want to keep this behavior)\n",
    "# Alternatively, add a new pad token:\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your policy prompt here.\n",
      "\n",
      "If you have a policy that you want to change, you can do so by clicking the button below.\n",
      "\n",
      "If you have a policy that you want to change, you can do so by clicking the button below.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = (input_ids != tokenizer.pad_token_id).long()  # Create attention mask\n",
    "\n",
    "# Generate text with attention mask\n",
    "output = model.generate(input_ids, attention_mask=attention_mask, max_length=150)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:601: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, attention_mask=attention_mask, max_length=150, temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your policy prompt here.\n",
      "\n",
      "If you're not sure, please click here to learn more.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "If you're not sure, click here.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "\n",
      "If you're not sure, click here.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "If you're not sure, click here to learn more.\n",
      "\n",
      "If you're not sure, click\n"
     ]
    }
   ],
   "source": [
    "prompt = \"give me policies of b\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "attention_mask = (input_ids != tokenizer.pad_token_id).long()  # Create attention mask\n",
    "\n",
    "# Generate text with attention mask and temperature\n",
    "output = model.generate(input_ids, attention_mask=attention_mask, max_length=150, temperature=0.7)\n",
    "\n",
    "# Decode and print the output\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
